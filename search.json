[
  {
    "objectID": "posts/brain-mri/brain-mri-blog.html",
    "href": "posts/brain-mri/brain-mri-blog.html",
    "title": "Brain MRI Detection with Interpretability",
    "section": "",
    "text": "Contents\n\nIntroduction\nDataset Exploration\nVision Transformer\nCLS-Attention\nAttention Rollout\nGradCAM\nConclusion\nReferences\n\n\n\n1. Introduction\nArtificial intelligence, particularly deep learning, has shown incredible promise in medical imaging. Models can now analyze scans like MRIs with an accuracy that rivals human experts. But there’s a catch: these models are often “black boxes.” They give us an answer, but they don’t tell us how they reached it.\nFor a doctor to trust an AI’s diagnosis, they need to see the evidence. This is where model interpretability becomes crucial.\nIn this post, we’ll walk through a complete project to not only train a Vision Transformer (ViT) to classify brain tumors from MRI scans but also to use powerful visualization techniques to see exactly what the model is “looking at” when it makes a prediction.\n\n\n2. Dataset Exploration\nThe dataset used is available easily in Kaggle, named: brain-tumor-mri-dataset. This dataset consists of about 7000 images of Brain MRIs, which contains images for three types of tumors (glioma, meningioma, and pituitary) as well as images of healthy brains (no tumor).\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport os \n\n# naming of folders for train and test dataset\ntrain, test = 'train', 'test'\n\n# downloading the data and exploring the types of labels\nbase_directory = \"dataset\" \ncategories = os.listdir(base_directory+ \"/\"+ train)\nprint(f'Categories are: {\", \".join(categories)}')\n\nCategories are: pituitary, notumor, meningioma, glioma\n\n\nLet’s see the images of each classes to get a hang of the dataset.\n\nimport matplotlib.pyplot as plt \nimport random \nfrom PIL import Image\n\n\ndef display_images(dataset_type, num_images=4, image_size=(224, 224)):\n    dataset_path = os.path.join(base_directory, dataset_type)\n    fig, axes = plt.subplots(len(categories), num_images, figsize=(15, 10))\n\n    for row, category in enumerate(categories):\n        category_path = os.path.join(dataset_path, category)\n        image_filenames = random.sample(os.listdir(category_path), num_images)  # Select random images\n        \n        for col, image_filename in enumerate(image_filenames):\n            while image_filename == '.DS_Store':\n                # sampling any random files of each category \n                image_filename = random.sample(os.listdir(category_path), 1)[0]\n            image_path = os.path.join(category_path, image_filename)\n            image = Image.open(image_path).resize(image_size)\n            axes[row, col].imshow(image, cmap='gray')\n            axes[row, col].axis('off')\n            axes[row, col].set_title(f\"{category}\")\n\n    plt.tight_layout()\n    plt.show()\n    \ndisplay_images('train', num_images=4)\n\n\n\n\n\n\n\n\nHere, we can see 4 different classes, with 3 types of tumor and 1 no tumor. The objective of the deep learning models will have to be predict the correct class of any image passed. We have trained a vision transformer for classifying the brain-mri images.\n\n\n3. Vision Transformer\n\nfrom torchvision import models\nimport torch \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}')\n\n# Load a pre-trained Vision Transformer\nmodel = models.vit_b_16(pretrained=False)\nprint(model) \n\nUsing device: cuda\nVisionTransformer(\n  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n  (encoder): Encoder(\n    (dropout): Dropout(p=0.0, inplace=False)\n    (layers): Sequential(\n      (encoder_layer_0): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_1): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_2): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_3): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_4): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_5): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_6): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_7): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_8): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_9): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_10): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (encoder_layer_11): EncoderBlock(\n        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (self_attention): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU(approximate='none')\n          (2): Dropout(p=0.0, inplace=False)\n          (3): Linear(in_features=3072, out_features=768, bias=True)\n          (4): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  )\n  (heads): Sequential(\n    (head): Linear(in_features=768, out_features=1000, bias=True)\n  )\n)\n\n\nFor this experiment, we used the vit_b_16 model. A key part of this procedure was implementing a robust data augmentation pipeline for the training set. This artificially expands the dataset and makes the model more resilient by teaching it to recognize tumors even if the images are:\n\nFlipped horizontally (RandomHorizontalFlip)\nSlightly shifted (RandomAffine)\nVaried in brightness (ColorJitter)\nRotated a bit (RandomRotation)\n\nThe training hyperparameters were as follows:\n\nModel: vit_b_16(pretrained=False)\nOptimizer: Adam with a learning rate of 1e-4.\nLoss Function: CrossEntropyLoss.\nLearning Rate Scheduler: StepLR, which reduces the learning rate by a set factor (gamma=0.5) every few epochs (step_size=5).\nBatch Size: 64\n\nWith these hyperparameters, VIT model was trained for about 100 epochs. However, the best perfomed model was obtained at epoch 32, after which the validation accuracy didn’t improve for about 10 more epochs. Thus, with the early stopping logic, the training stopped.\nThe metrics of the saved model was:\nTrain Loss: 0.2863 Acc: 0.8857 | Val Loss: 0.3044 Acc: 0.8750\n \nWhen inferred with the test_dataset, the accuracy obtained was 89% with the confusion matrix as follows:\n\nOur model achieved high accuracy, but we still need to know why it works. We’ll use two powerful techniques to create heatmaps that highlight the most important regions in the MRI scan for a given prediction.\n\n[CLS] Token Attention: The Vision Transformer uses a special [CLS] token to aggregate information from the entire image to make a final decision. By visualizing this token’s attention, we can see which parts of the image it focused on. We will look at this attention for every layer to see how its focus evolves.\nGrad-CAM: It uses the model’s internal gradients to create a heatmap that answers the question: “Which pixels provided the most evidence for the ‘glioma’ prediction?”\n\nLet us initialize the dataloaders, and select a test image for visualization.\n\nimport utils \nfrom transformers import ViTForImageClassification, ViTConfig\nimport torch \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport cv2 \n\n\nIMAGE_SIZE = 224\nPATCH_SIZE = 16\nNUM_PATCHES_SIDE = IMAGE_SIZE // PATCH_SIZE\n\ntest_dataset, test_loader, _, _, data_vars = utils.read_data(data_mode='test', batch_size=4)\ncategories = data_vars['categories']\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}')\n\n# only getting the architecture\nconfig = ViTConfig.from_pretrained(\n    'google/vit-base-patch16-224-in21k',\n    num_labels=len(categories),\n    output_attentions=True,\n    image_size=IMAGE_SIZE\n)\n\nmodel = ViTForImageClassification(config)\nmodel = model.to(device)\n\n# best_model.pt is the saved model \nmodel.load_state_dict(torch.load('best_model.pt', map_location=device))\nmodel.eval()\nprint(\"\\nSuccessfully loaded model weights.\")\n\ntest_img, test_label = next(iter(test_loader))\ntest_img_tensor = test_img.to(device)\n\noutputs = model(test_img_tensor, output_attentions=True)\nall_layer_attentions = outputs.attentions\nlogits = outputs.logits\npredicted_class_indices = torch.argmax(logits, dim=-1)\n\n\n# taking one single image for analysis\nimage_index = 0\nimage_to_analyze_b1 = test_img_tensor[image_index:image_index+1]\npredicted_class_idx = predicted_class_indices[image_index].item()\npredicted_label = categories[predicted_class_idx]\n\noriginal_img_tensor = test_img_tensor[image_index]\nimg_np = original_img_tensor.cpu().numpy().transpose((1, 2, 0))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nimg_np = std * img_np + mean\nimg_np = np.clip(img_np, 0, 1)\n\n\nprint(f\"\\nDisplaying input image #{image_index} which was predicted as: {predicted_label}\")\nplt.figure(figsize=(6, 6))\nplt.imshow(img_np)\nplt.title(f\"Input Image | Predicted: {predicted_label}\")\nplt.axis('off')\nplt.show()\n\ncuda\nLength of test dataset: 655\nLength of val dataset: 656\nUsing device: cuda\n\nSuccessfully loaded model weights.\n\nDisplaying input image #0 which was predicted as: glioma\n\n\n\n\n\n\n\n\n\n\ndef plot_heatmap_on_ax(ax, img_np, heatmap, title):\n    \"\"\"Helper function to plot a heatmap overlay on an image axis.\"\"\"\n    heatmap_grid = heatmap.reshape(NUM_PATCHES_SIDE, NUM_PATCHES_SIDE)\n    heatmap_resized = cv2.resize(heatmap_grid.cpu().detach().numpy(), (IMAGE_SIZE, IMAGE_SIZE))\n    ax.imshow(img_np)\n    ax.imshow(heatmap_resized, cmap='viridis', alpha=0.5)\n    ax.set_title(title)\n    ax.axis('off')\n\n\n\n4. CLS-Attention\nIn a Vision Transformer, the CLS token is the representation used for classification. To understand why the model made a prediction, we want to see what the CLS token is looking at in the image. CLS attention evolves from global to object-focused across layers. Hence, we will try to visualize it across all layers to see which area of the image contributed more to the classification done by out VIT model.\n\ndef visualize_layerwise_cls_attention(all_layer_attentions, img_np, predicted_label):    \n    print(\"\\nGenerating Grid Visualization: Layer-wise [CLS] Attention\")\n    fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n    fig.suptitle(f\"Layer-wise [CLS] Token Attention | Predicted: {predicted_label}\", fontsize=24)\n    axs = axs.flatten()\n\n    for i in range(12):\n        layer_attention = all_layer_attentions[i]\n        cls_attention_map = torch.mean(layer_attention, dim=1)[0, 0, 1:] # Avg heads, get CLS row\n        plot_heatmap_on_ax(axs[i], img_np, cls_attention_map, f\"Layer {i+1} Attention\")\n        \n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\nimage_attentions_cls_tuple = tuple(att[image_index:image_index+1] for att in all_layer_attentions)\nvisualize_layerwise_cls_attention(image_attentions_cls_tuple, img_np, predicted_label)\n\n\nGenerating Grid Visualization: Layer-wise [CLS] Attention\n\n\n\n\n\n\n\n\n\nIn the early layers, the model acts like a low-level feature detector.\n\nLayer 1: The attention is highly localized on a small, distinct feature on the left side of the brain. The model isn’t seeing a “tumor” yet; it’s seeing a “bright spot,” an “edge,” or an interesting “texture.”\nLayers 2-4: The attention starts to diffuse slightly, picking up on other interesting low-level features across the brain. It’s still gathering basic visual evidence without a high-level understanding.\nLayer 5 & 6: The attention starts to group the initial features, becoming less about individual spots and more about regions.\nLayer 7 & 8: The attention becomes much broader. The model is no longer just looking at the tumor itself but is now paying attention to the entire upper region of the brain. It seems to have learned that the features of a glioma exist within a larger anatomical context.\nLayers 9 & 10: The attention is now very broad and confident, covering the entire pathological area. The model has concluded that this whole upper region of the brain is relevant to the “glioma” classification. This is a sign of a sophisticated model—it’s not just finding a single point of evidence but recognizing a widespread pattern.\nLayers 11 & 12: The attention remains broad, representing the final, aggregated evidence from all previous layers. This holistic view is what feeds into the classification head to make the final prediction of “glioma.”\n\n\n\n5. Attention Rollout\nA Vision Transformer (ViT) is composed of multiple layers of self-attention. While it’s tempting to just look at the final layer’s attention map to see what the model is focusing on, this can be misleading. The final layer’s attention is applied to embeddings that are already a complex mixture of the initial embeddings from all previous layers.\nAttention Rollout is a technique proposed by Abnar & Zuidema (2020) to better approximate the full attention flow through the network. It aggregates the attention matrices from all layers to create a single map that shows how much each input token contributes to the output tokens.\n\n\nSteps\n\nStart with the first layer’s attention\nall_layer_attentions[0] contains the attention weights for the first transformer layer (shape: [batch, heads, tokens, tokens]). torch.mean(..., dim=1) averages across all the attention heads, so we get one attention map per layer instead of per head. This becomes our initial rollout.\nWe iterate through the remaining layers\n\nFor each layer, we average over the heads (torch.mean).\nAdd an identity matrix to the attention map. This makes sure that each token can always “attend to itself” (preserving direct connections).\nWe multiply (torch.matmul) the current layer’s attention with the accumulated rollout. This composes the attentions across layers, so we capture how attention paths stack together as we move deeper in the network.\nWe extract how the CLS token looks at the image patches After processing all layers, rollout contains the cumulative influence of each token on every other token.\n\nrollout[:, 0, 1:] selects:\n\nRow 0 → corresponds to the CLS token.\nColumns 1: → corresponds to the patch tokens (ignoring CLS itself). This gives us the final attention rollout map showing which image patches the CLS token (used for classification) is attending to, across the whole network.\n\n\n\ndef calculate_attention_rollout(all_layer_attentions):\n    \"\"\"\n    Computes attention rollout across all layers \n    \"\"\"\n    # 1: Start with the first layer's attention\n    # Average across attention heads → one attention map per layer\n    # Shape: [batch, tokens, tokens]\n    rollout = torch.mean(all_layer_attentions[0], dim=1)\n\n    # 2: Iterate through the remaining layers\n    for i in range(1, len(all_layer_attentions)):\n        # average attention heads for this layer\n        attn_map = torch.mean(all_layer_attentions[i], dim=1)\n\n        # identity matrix \n        identity = torch.eye(attn_map.shape[-1], device=attn_map.device)\n        attn_map = attn_map + identity\n\n        # Multiply with accumulated rollout to stack attention paths\n        rollout = torch.matmul(attn_map, rollout)\n\n    # 3: Extract CLS → patch token attention\n    # CLS token is at index 0, patches are from index 1 onwards\n    # Shape: [batch, tokens-1]\n    cls_rollout = rollout[:, 0, 1:]\n    return cls_rollout\n\n\ndef visualize_attention_rollout(all_layer_attentions, img_np, predicted_label):\n    \"\"\"\n    Calculates and visualizes the combined Attention Rollout map.\n    \"\"\"\n    print(\"\\nGenerating Visualization: Attention Rollout:\")\n    \n    # rollout map from the function\n    rollout_map = calculate_attention_rollout(all_layer_attentions)\n    \n    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n    fig.suptitle(f\"Attention Rollout | Predicted: {predicted_label}\", fontsize=16)\n    plot_heatmap_on_ax(ax, img_np, rollout_map.squeeze(), \"Aggregated Attention from All Layers\")    \n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\nimage_attentions_tuple = tuple(att[image_index:image_index+1] for att in all_layer_attentions)\nvisualize_attention_rollout(image_attentions_tuple, img_np, predicted_label)\n\n\nGenerating Visualization: Attention Rollout:\n\n\n\n\n\n\n\n\n\n\n\n6. Grad-CAM\nGradient-weighted Class Activation Mapping (Grad-CAM) is a powerful technique for interpretation. It uses the gradients of the final prediction to highlight the evidence in the image.\nTo implement this, we need to grab internal data from the model during a forward and backward pass. The cleanest way to do this in PyTorch is with hooks. A hook is like a listener device we can attach to a model layer to inspect the data flowing through it without permanently changing the model’s code. The captured gradients tell us the importance of each feature channel in our target layer. We average these gradients to get a single importance weight per channel.\nWe compute a weighted average of the activations, using the weights we just calculated. The torch.einsum function is a highly efficient way to do this. This weighted sum is our heatmap. We apply a ReLU function to ensure we only see the features that had a positive contribution to the final decision.\nWe implement this for visualizing all layers’ gradients and activations, so as to see the different areas each layer focused while processing the image.\n\nclass ViTGradCAM:\n    \"\"\"A class to generate Grad-CAM heatmaps for a Vision Transformer model.\"\"\"\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.activations = None\n        self._register_hooks()\n\n    def _capture_activations(self, module, input, output):\n        self.activations = output\n\n    def _capture_gradients(self, module, grad_in, grad_out):\n        self.gradients = grad_out[0]\n\n    def _register_hooks(self):\n        # adding hooks\n        self.forward_handle = self.target_layer.register_forward_hook(self._capture_activations)\n        self.backward_handle = self.target_layer.register_full_backward_hook(self._capture_gradients)\n\n    def remove_hooks(self):\n        self.forward_handle.remove()\n        self.backward_handle.remove()\n\n    def __call__(self, input_tensor, class_idx):\n        self.model.zero_grad()\n        logits = self.model(input_tensor).logits\n        target_score = logits[:, class_idx].sum()\n        target_score.backward(retain_graph=True)\n        gradients = self.gradients\n        activations = self.activations\n        weights = torch.mean(gradients, dim=1)\n        cam = torch.einsum('bpd,bd-&gt;bp', activations, weights)\n        \n        # applying relu\n        cam = torch.relu(cam)\n        return cam[:, 1:]\n\n\ndef visualize_layerwise_grad_cam(model, image_to_analyze_b1, img_np, predicted_class_idx, predicted_label):\n    print(\"\\nGenerating Grid Visualization: Layer-wise Grad-CAM\")\n    fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n    fig.suptitle(f\"Layer-wise Grad-CAM | Predicted: {predicted_label}\", fontsize=24)\n    axs = axs.flatten()\n\n    # visualizing the gradients for all layers in VIT\n    for i in range(12):\n        try:\n            target_layer = model.vit.encoder.layer[i].output\n            grad_cam = ViTGradCAM(model, target_layer=target_layer)\n            cam_map = grad_cam(image_to_analyze_b1, class_idx=predicted_class_idx).squeeze()\n            \n            # removing hooks so it won't affect further tasks\n            grad_cam.remove_hooks()\n            plot_heatmap_on_ax(axs[i], img_np, cam_map, f\"Layer {i+1} Grad-CAM\")\n        except Exception as e:\n            print(f\"Could not generate Grad-CAM for layer {i+1}: {e}\")\n            axs[i].set_title(f\"Layer {i+1} Grad-CAM (Error)\")\n            axs[i].axis('off')\n            \n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\nvisualize_layerwise_grad_cam(model, image_to_analyze_b1, img_np, predicted_class_idx, predicted_label)\n\n\nGenerating Grid Visualization: Layer-wise Grad-CAM\n\n\n\n\n\n\n\n\n\nUnlike attention maps which show focus, Grad-CAM shows the importance for the final prediction at each layer. The early layers act like a basic feature extractor, searching for simple patterns like edges, textures, and gradients. The heatmaps are sparse and tend to highlight the outer edges of the head and skull rather than the brain tissue itself. The heatmaps in mid layers[5-8] move inward, and by Layers 7 and 8, a clear, focused hotspot appears directly over the location of the tumor in the upper left of the brain. In the last 4 layers, the focused hotspot from the middle layers disappears, and the heatmaps become extremely broad and diffuse, eventually covering the entire brain and surrounding area. It depicts that the tumor is present in the image, showcasing the entire figure of the image as evidence.\n\n\n7. Conclusion\nIn this post, we’ve gone from a dataset of MRI scans to a fully trained Vision Transformer capable of accurately classifying brain tumors. But more importantly, we’ve denied to accept the model as a “black box.” Through layer-wise attention and Grad-CAM visualizations, we’ve demonstrated that our model is behaving logically. We witnessed its focus evolve from simple textures and edges in the early layers to complex, semantic concepts in the later ones.\nIt’s important to frame these visualizations correctly. While techniques like Grad-CAM and Attention Rollout provide powerful insights, they are still approximations of a highly complex internal process. They may not perfectly capture the model’s complete reasoning, but they serve a crucial purpose: they build confidence. They show us that the model is not relying on random artifacts in the image but is learning relevant, medically significant patterns.\n\n\n8. References\n\nAN IMAGE IS WORTH 16X16 WORDS\nQuantifying Attention Flow in Transformers\nBrain Tumor Dataset\nGradCAM"
  },
  {
    "objectID": "posts/Gradient-Schmidt/algo.html",
    "href": "posts/Gradient-Schmidt/algo.html",
    "title": "Understanding Gram-Schmidt",
    "section": "",
    "text": "Table of Contents\n\nObjective\nIntroduction\nObtaining Orthogonal Vectors\nNormalization\nConclusion\n\n\n\nObjective\n\nStart with 2 independent vectors a and b\nfind orthonormal vectors q1 and q2 that span the same plane\nfind orthogonal vectors first A, B\n\n\n\nIntroduction\nIn linear algebra and data science, having a set of orthonormal vectors is incredibly useful. They form a basis that simplifies calculations and is the backbone of powerful techniques like Principal Component Analysis (PCA) and QR decomposition. But what if the starting vectors aren’t orthonormal? That’s where the Gram-Schmidt algorithm comes in.\nOrthogonal Vectors: if their dot product is 0\nOrthonormal Vectors: if their dot product is 0 and their lengths are 1\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef plot_vectors_3d(vectors, colors=['blue', 'red'], title=\"3D Vector Plot\"):\n    fig = plt.figure(figsize=(8, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    # Plot each vector with its corresponding color\n    for (name, vec), color in zip(vectors.items(), colors):\n        ax.quiver(0, 0, 0, vec[0], vec[1], vec[2], color=color, label=name, arrow_length_ratio=0.1)\n\n\n    ax.set_xlim([-2, 2])\n    ax.set_ylim([-2, 2])\n    ax.set_zlim([-2, 2])\n    ax.set_xlabel('X axis')\n    ax.set_ylabel('Y axis')\n    ax.set_zlabel('Z axis')\n    ax.set_title(title)\n    ax.legend()\n    plt.show()\n\n\nimport numpy as np\n\nLet’s start with two vectors, a and b. Our goal is to find two new vectors, q1 and q2, that are orthonormal but span the exact same plane as a and b.\n\na = np.array([1,1,1])\nb = np.array([1,0,2])\nprint(a.shape, b.shape)\ninitial_vectors = {'a': a, 'b': b}\nplot_vectors_3d(initial_vectors, title=\"Initial Vectors a and b\")\n\n(3,) (3,)\n\n\n\n\n\n\n\n\n\n\n\nObtaining Orthogonal Vectors\nWe’ll pick our first vector, a, and call it A. This is our first basis vector. Now, for the second vector b, we need to make it orthogonal to A. We do this by calculating the ‘shadow’ that b casts on A (its projection) and subtracting it from b. What’s left is a new vector, B, that is perfectly perpendicular (orthogonal) to A.\nMathematically, \\[\nA=a \\\\ \\\\\nB = b- \\frac{A^Tb}{A^TA}A\n\\]\nImplementing the above equations in code.\n\ndef getB(A, b):\n    \n    num = np.dot(A.T, b)\n    den = np.dot(A.T, A)\n    frac = num/den \n    B = b - np.dot(frac, A)\n    return B\n\n\nA = a \nB = getB(A, b)\nprint(f'A:\\n{A},\\nB:\\n{B}')\n\northogonal_vectors = {'A': A, 'B': B}\nplot_vectors_3d(orthogonal_vectors, title=\"Orthogonal Vectors A and B\")\n\nA:\n[1 1 1],\nB:\n[ 0. -1.  1.]\n\n\n\n\n\n\n\n\n\n\ndot_product = np.dot(A, B)\nprint(f'Dot product is {dot_product}!')\n\n# length of vector\nlen_A = np.linalg.norm(A, ord=2)\nlen_B = np.linalg.norm(B, ord=2)\nprint(f'Length of A is {len_A}\\nLength of B is {len_B}')\n\nDot product is 0.0!\nLength of A is 1.7320508075688772\nLength of B is 1.4142135623730951\n\n\nThe dot product is 0.0, which confirms A and B are orthogonal! However, we can see their lengths are not 1. This means they are an orthogonal basis, but not yet an orthonormal one.\n\nA/np.linalg.norm(A, ord=2), np.linalg.norm(A/np.linalg.norm(A, ord=2), ord=2)\n\n(array([0.57735027, 0.57735027, 0.57735027]), 1.0)\n\n\n\n\nNormalization\nTo make our vectors have a length of 1, we simply divide each vector by its own magnitude (its L2 norm). It is called normalization.\n\\[\nQ1 = \\frac{A}{||A||} \\\\\nQ2 = \\frac{B}{||B||}\n\\]\n\n# getting orthonormal vectors \ndef getQ(A, B):\n    return A/np.linalg.norm(A, ord=2), B/np.linalg.norm(B, ord=2)\n\n\nQ1, Q2 = getQ(A, B)\n\nprint(f'Q1:\\n{Q1},\\nQ2:\\n{Q2}')\n\northonormal_vectors = {'Q1': Q1, 'Q2': Q2}\nplot_vectors_3d(orthonormal_vectors, title=\"Final Orthonormal Vectors Q1 and Q2\")\n\nQ1:\n[0.57735027 0.57735027 0.57735027],\nQ2:\n[ 0.         -0.70710678  0.70710678]\n\n\n\n\n\n\n\n\n\n\ndot_product = np.round(np.dot(Q1, Q2), decimals=3)\nprint(f'Dot product is {dot_product}!')\n\n# length of vector\nlen_Q1 = np.round(np.linalg.norm(Q1, ord=2), decimals=3)\nlen_Q2 = np.round(np.linalg.norm(Q2, ord=2), decimals=3)\nprint(f'Length of Q1 is {len_Q1}\\nLength of Q2 is {len_Q2}')\n\nDot product is 0.0!\nLength of Q1 is 1.0\nLength of Q2 is 1.0\n\n\nThere we go! The dot product of Q1 and Q2 is 0, and their lengths are both 1. We have successfully converted our initial vectors into an orthonormal basis.\n\n\nReferences:\n\nOrthogonal Matrices: MIT Linear Algebra 2017\nOrthogonal and Orthonormal Vectors: James McCaffrey Wordpress"
  },
  {
    "objectID": "posts/pytorch_gradients.html",
    "href": "posts/pytorch_gradients.html",
    "title": "Pytorch Grad!",
    "section": "",
    "text": "At the heart of how almost every modern machine learning model learns is a process called gradient descent. The core idea is to minimize a “loss” function, which is a score that tells us how wrong our model’s predictions are.\nCalculating the gradients for complex models used to involve pages of manual calculus. This is where PyTorch’s autograd engine comes in—it automatically computes these gradients for us, forming the backbone of deep learning. Let’s see how it works with a simple example.\n\nimport torch\n\nWe’ll start with a random guess for the weight w and use gradient descent to guide it toward the true value of 2.\n\n# We want to find a 'w' such that y is close to w * x.\n# The true 'w' is clearly 2.\nX = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=torch.float32)\nY = torch.tensor([2.0, 4.0, 6.0, 8.0], dtype=torch.float32)\n\n# Initialize our weight 'w' with a random guess.\n# requires_grad=True tells PyTorch to track this tensor for gradient calculations.\nw = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n\nThe key here is requires_grad=True. This tag the w tensor, telling PyTorch’s autograd engine to keep track of every operation involving it so it can later compute gradients.\n\ndef forward(x):\n    return w * x\n\ndef loss(y, y_predicted):\n    return ((y_predicted - y)**2).mean()\n\nlearning_rate = 0.01\nn_iters = 20\n\n\n\nprint(f\"Starting training... Initial weight w = {w.item():.3f}\")\nweights_history = []\nloss_history = []\nfor epoch in range(n_iters):\n    # Forward pass\n    y_pred = forward(X)\n\n    # loss\n    l = loss(Y, y_pred)\n    weights_history.append(w.item())\n    loss_history.append(l.item())\n\n    # Calculate gradients = backward pass\n    # core of autograd. It calculates the derivative of 'l'\n    # with respect to every tensor that has requires_grad=True (i.e., 'w').\n    l.backward() # dl/dw\n\n    # Manually update weights\n    # torch.no_grad() because this is not part of the computation graph\n    with torch.no_grad():\n        # The calculated gradient is now in w.grad\n        # Update rule: w = w - learning_rate * gradient\n        w.data -= learning_rate * w.grad\n\n    # Zero out the gradients for the next iteration\n    if (epoch + 1) % 2 == 0:\n        print(f'Epoch {epoch+1}: w = {w.item():.3f}, w gradient: {w.grad}, loss = {l.item():.8f}')\n\n    w.grad.zero_()\n\n    # if (epoch + 1) % 2 == 0:\n    #     print(f'Epoch {epoch+1}: w = {w.item():.3f}, w gradient: {w.grad}, loss = {l.item():.8f}')\n\nprint(f\"\\nTraining finished. The learned weight is: {w.item():.3f}\")\nprint(\"The true weight was 2.0\")\n\nStarting training... Initial weight w = 0.000\nEpoch 2: w = 0.555, w gradient: -25.5, loss = 21.67499924\nEpoch 4: w = 0.956, w gradient: -18.423751831054688, loss = 11.31448650\nEpoch 6: w = 1.246, w gradient: -13.311159133911133, loss = 5.90623236\nEpoch 8: w = 1.455, w gradient: -9.61731243133545, loss = 3.08308983\nEpoch 10: w = 1.606, w gradient: -6.948507308959961, loss = 1.60939169\nEpoch 12: w = 1.716, w gradient: -5.020296096801758, loss = 0.84011245\nEpoch 14: w = 1.794, w gradient: -3.627163887023926, loss = 0.43854395\nEpoch 16: w = 1.851, w gradient: -2.6206254959106445, loss = 0.22892261\nEpoch 18: w = 1.893, w gradient: -1.8934016227722168, loss = 0.11949898\nEpoch 20: w = 1.922, w gradient: -1.3679819107055664, loss = 0.06237914\n\nTraining finished. The learned weight is: 1.922\nThe true weight was 2.0\n\n\nThe plots below show the loss steadily decreasing while the weight w converges towards its target value.\n\nimport matplotlib.pyplot as plt \n\n# Create the plots\nfig = plt.figsize=(8, 10)\n\n# Plot 1: Loss vs. Epochs\nplt.plot(loss_history, 'r-')\nplt.title(\"Loss vs. Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Create the plots\nfig = plt.figsize=(8, 10)\n\n# Plot 2: Weight vs. Epochs\nplt.plot(weights_history, 'b-')\nplt.axhline(y=2.0, color='g', linestyle='--', label=\"True Weight\") # Add line for the true weight\nplt.title(\"Weight (w) vs. Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Weight (w)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nWhile our example was simple, these exact principles: defining a model, calculating loss, and using autograd to update parameters, power the training of massive neural networks."
  },
  {
    "objectID": "posts/basic_deep_learning.html",
    "href": "posts/basic_deep_learning.html",
    "title": "Deep Learning Concepts",
    "section": "",
    "text": "The Perceptron is the simplest form of a neural network. It’s a single neuron that takes binary inputs, applies weights and a bias, and uses a step function to produce a binary output. It can only solve linearly separable problems.\nThe formula is: \\(y = f(\\sum_{i} w_i x_i + b)\\), where \\(f\\) is a step function.\n\\(f(x) = \\begin{cases} 1 & \\text{if } x \\geq 0 \\\\ 0 & \\text{if } x &lt; 0 \\end{cases}\\)\n\nimport matplotlib.pyplot as plt \n\n\nimport numpy as np\n\nclass Perceptron:\n    \"\"\"A simple Perceptron classifier.\"\"\"\n    def __init__(self, learning_rate=0.1, n_iters=100):\n        self.lr = learning_rate\n        self.n_iters = n_iters\n        self.activation_func = self._step_function\n        self.weights = None\n        self.bias = None\n\n    def _step_function(self, x):\n        return np.where(x &gt;= 0, 1, 0)\n\n    def fit(self, X, y):\n        print('Beginning to fit')\n        n_samples, n_features = X.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        for i in range(self.n_iters):\n            for idx, x_i in enumerate(X):\n                linear_output = np.dot(x_i, self.weights) + self.bias\n                y_predicted = self.activation_func(linear_output)\n\n                # Perceptron update rule\n                update = self.lr * (y[idx] - y_predicted)\n                self.weights += update * x_i\n                self.bias += update\n\n            if i%10==0:\n                print(i)\n\n    def predict(self, X):\n        linear_output = np.dot(X, self.weights) + self.bias\n        return self.activation_func(linear_output)\n\n    def show(self):\n        fig, ax = plt.subplots(figsize=(4, 2))\n        ax.axis('off')\n\n        # Input layer (2 inputs)\n        ax.add_patch(plt.Circle((0.5, 1), 0.1, color='skyblue', ec='black'))\n        ax.text(0.3, 1, \"$x_1$\", fontsize=12)\n        ax.add_patch(plt.Circle((0.5, 0.5), 0.1, color='skyblue', ec='black'))\n        ax.text(0.3, 0.5, \"$x_2$\", fontsize=12)\n\n        # Output neuron\n        ax.add_patch(plt.Circle((2, 0.75), 0.12, color='salmon', ec='black'))\n        ax.text(2.2, 0.75, \"$\\hat{y}$\", fontsize=12)\n\n        # Arrows\n        ax.annotate(\"\", xy=(1.88, 0.75), xytext=(0.6, 1), arrowprops=dict(arrowstyle='-&gt;'))\n        ax.annotate(\"\", xy=(1.88, 0.75), xytext=(0.6, 0.5), arrowprops=dict(arrowstyle='-&gt;'))\n\n        ax.set_title(\"Perceptron Architecture\", fontsize=14)\n        plt.xlim(0, 2.5)\n        plt.ylim(0.2, 1.3)\n        plt.tight_layout()\n        plt.show()\n\n&lt;&gt;:51: SyntaxWarning: invalid escape sequence '\\h'\n&lt;&gt;:51: SyntaxWarning: invalid escape sequence '\\h'\n/tmp/ipykernel_65160/2482501332.py:51: SyntaxWarning: invalid escape sequence '\\h'\n  ax.text(2.2, 0.75, \"$\\hat{y}$\", fontsize=12)\n\n\n\nmodel = Perceptron()\n\n\nmodel.show()\n\n\n\n\n\n\n\n\n\n# Generate data \nx_vals = np.linspace(-5, 5, 500)\ny_step = model._step_function(x_vals)\n\n# Create the plot\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(x_vals, y_step, label='Step Function')\nplt.title('Step Activation Function')\nplt.xlabel('Input value (x)')\nplt.ylabel('Output value')\nplt.ylim(-0.1, 1.1)\nplt.legend()\nprint(\"Step Function: Outputs 0 for negative input, 1 for positive. Used in the original Perceptron.\")\n\nStep Function: Outputs 0 for negative input, 1 for positive. Used in the original Perceptron.\n\n\n\n\n\n\n\n\n\n\n\nThe XOR (exclusive OR) gate is a classic example of a non-linearly separable problem. A single straight line cannot separate the (0,1) and (1,0) points from (0,0) and (1,1).\n\n# XOR problem data\nX_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny_xor = np.array([0, 1, 1, 0])\n\nplt.figure(figsize=(5, 5))\nfor label in np.unique(y_xor):\n    plt.scatter(\n        X_xor[y_xor == label, 0], \n        X_xor[y_xor == label, 1], \n        label=f\"Class {label}\", \n        edgecolor='k', \n        s=100\n    )\n\nplt.title(\"XOR Dataset\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.xticks([0, 1])\nplt.yticks([0, 1])\nplt.grid(True)\nplt.legend()\nplt.axis('equal')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Train the perceptron\nperceptron = Perceptron(learning_rate=0.1, n_iters=100)\nperceptron.fit(X_xor, y_xor)\n\nBeginning to fit\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n\n\n\nprint(\"\\n=== Perceptron Model Structure ===\")\nprint(f\"Number of layers: 1 (no hidden layer)\")\nprint(f\"Weights shape: {perceptron.weights.shape}\")\nprint(f\"Bias: {perceptron.bias}\")\n\n\n=== Perceptron Model Structure ===\nNumber of layers: 1 (no hidden layer)\nWeights shape: (2,)\nBias: 0.0\n\n\n\n# Get predictions\npredictions = perceptron.predict(X_xor)\n\nprint(f\"XOR Input:\\n{X_xor}\")\nprint(f\"Expected Output: {y_xor}\")\nprint(f\"Perceptron Output: {predictions}\")\naccuracy = np.sum(y_xor == predictions) / len(y_xor)\nprint(f\"Accuracy: {accuracy * 100}%\")\nprint(\"\\nAs you can see, the single-layer Perceptron cannot learn the XOR function.\")\n\nXOR Input:\n[[0 0]\n [0 1]\n [1 0]\n [1 1]]\nExpected Output: [0 1 1 0]\nPerceptron Output: [1 1 0 0]\nAccuracy: 50.0%\n\nAs you can see, the single-layer Perceptron cannot learn the XOR function."
  },
  {
    "objectID": "posts/basic_deep_learning.html#the-perceptron-a-single-linear-neuron",
    "href": "posts/basic_deep_learning.html#the-perceptron-a-single-linear-neuron",
    "title": "Deep Learning Concepts",
    "section": "",
    "text": "The Perceptron is the simplest form of a neural network. It’s a single neuron that takes binary inputs, applies weights and a bias, and uses a step function to produce a binary output. It can only solve linearly separable problems.\nThe formula is: \\(y = f(\\sum_{i} w_i x_i + b)\\), where \\(f\\) is a step function.\n\\(f(x) = \\begin{cases} 1 & \\text{if } x \\geq 0 \\\\ 0 & \\text{if } x &lt; 0 \\end{cases}\\)\n\nimport matplotlib.pyplot as plt \n\n\nimport numpy as np\n\nclass Perceptron:\n    \"\"\"A simple Perceptron classifier.\"\"\"\n    def __init__(self, learning_rate=0.1, n_iters=100):\n        self.lr = learning_rate\n        self.n_iters = n_iters\n        self.activation_func = self._step_function\n        self.weights = None\n        self.bias = None\n\n    def _step_function(self, x):\n        return np.where(x &gt;= 0, 1, 0)\n\n    def fit(self, X, y):\n        print('Beginning to fit')\n        n_samples, n_features = X.shape\n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        for i in range(self.n_iters):\n            for idx, x_i in enumerate(X):\n                linear_output = np.dot(x_i, self.weights) + self.bias\n                y_predicted = self.activation_func(linear_output)\n\n                # Perceptron update rule\n                update = self.lr * (y[idx] - y_predicted)\n                self.weights += update * x_i\n                self.bias += update\n\n            if i%10==0:\n                print(i)\n\n    def predict(self, X):\n        linear_output = np.dot(X, self.weights) + self.bias\n        return self.activation_func(linear_output)\n\n    def show(self):\n        fig, ax = plt.subplots(figsize=(4, 2))\n        ax.axis('off')\n\n        # Input layer (2 inputs)\n        ax.add_patch(plt.Circle((0.5, 1), 0.1, color='skyblue', ec='black'))\n        ax.text(0.3, 1, \"$x_1$\", fontsize=12)\n        ax.add_patch(plt.Circle((0.5, 0.5), 0.1, color='skyblue', ec='black'))\n        ax.text(0.3, 0.5, \"$x_2$\", fontsize=12)\n\n        # Output neuron\n        ax.add_patch(plt.Circle((2, 0.75), 0.12, color='salmon', ec='black'))\n        ax.text(2.2, 0.75, \"$\\hat{y}$\", fontsize=12)\n\n        # Arrows\n        ax.annotate(\"\", xy=(1.88, 0.75), xytext=(0.6, 1), arrowprops=dict(arrowstyle='-&gt;'))\n        ax.annotate(\"\", xy=(1.88, 0.75), xytext=(0.6, 0.5), arrowprops=dict(arrowstyle='-&gt;'))\n\n        ax.set_title(\"Perceptron Architecture\", fontsize=14)\n        plt.xlim(0, 2.5)\n        plt.ylim(0.2, 1.3)\n        plt.tight_layout()\n        plt.show()\n\n&lt;&gt;:51: SyntaxWarning: invalid escape sequence '\\h'\n&lt;&gt;:51: SyntaxWarning: invalid escape sequence '\\h'\n/tmp/ipykernel_65160/2482501332.py:51: SyntaxWarning: invalid escape sequence '\\h'\n  ax.text(2.2, 0.75, \"$\\hat{y}$\", fontsize=12)\n\n\n\nmodel = Perceptron()\n\n\nmodel.show()\n\n\n\n\n\n\n\n\n\n# Generate data \nx_vals = np.linspace(-5, 5, 500)\ny_step = model._step_function(x_vals)\n\n# Create the plot\nplt.figure(figsize=(12, 8))\n\nplt.subplot(2, 2, 1)\nplt.plot(x_vals, y_step, label='Step Function')\nplt.title('Step Activation Function')\nplt.xlabel('Input value (x)')\nplt.ylabel('Output value')\nplt.ylim(-0.1, 1.1)\nplt.legend()\nprint(\"Step Function: Outputs 0 for negative input, 1 for positive. Used in the original Perceptron.\")\n\nStep Function: Outputs 0 for negative input, 1 for positive. Used in the original Perceptron.\n\n\n\n\n\n\n\n\n\n\n\nThe XOR (exclusive OR) gate is a classic example of a non-linearly separable problem. A single straight line cannot separate the (0,1) and (1,0) points from (0,0) and (1,1).\n\n# XOR problem data\nX_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny_xor = np.array([0, 1, 1, 0])\n\nplt.figure(figsize=(5, 5))\nfor label in np.unique(y_xor):\n    plt.scatter(\n        X_xor[y_xor == label, 0], \n        X_xor[y_xor == label, 1], \n        label=f\"Class {label}\", \n        edgecolor='k', \n        s=100\n    )\n\nplt.title(\"XOR Dataset\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.xticks([0, 1])\nplt.yticks([0, 1])\nplt.grid(True)\nplt.legend()\nplt.axis('equal')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Train the perceptron\nperceptron = Perceptron(learning_rate=0.1, n_iters=100)\nperceptron.fit(X_xor, y_xor)\n\nBeginning to fit\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n\n\n\nprint(\"\\n=== Perceptron Model Structure ===\")\nprint(f\"Number of layers: 1 (no hidden layer)\")\nprint(f\"Weights shape: {perceptron.weights.shape}\")\nprint(f\"Bias: {perceptron.bias}\")\n\n\n=== Perceptron Model Structure ===\nNumber of layers: 1 (no hidden layer)\nWeights shape: (2,)\nBias: 0.0\n\n\n\n# Get predictions\npredictions = perceptron.predict(X_xor)\n\nprint(f\"XOR Input:\\n{X_xor}\")\nprint(f\"Expected Output: {y_xor}\")\nprint(f\"Perceptron Output: {predictions}\")\naccuracy = np.sum(y_xor == predictions) / len(y_xor)\nprint(f\"Accuracy: {accuracy * 100}%\")\nprint(\"\\nAs you can see, the single-layer Perceptron cannot learn the XOR function.\")\n\nXOR Input:\n[[0 0]\n [0 1]\n [1 0]\n [1 1]]\nExpected Output: [0 1 1 0]\nPerceptron Output: [1 1 0 0]\nAccuracy: 50.0%\n\nAs you can see, the single-layer Perceptron cannot learn the XOR function."
  },
  {
    "objectID": "posts/basic_deep_learning.html#multilayer-perceptron-mlp-for-xor",
    "href": "posts/basic_deep_learning.html#multilayer-perceptron-mlp-for-xor",
    "title": "Deep Learning Concepts",
    "section": "2. Multilayer Perceptron (MLP) for XOR",
    "text": "2. Multilayer Perceptron (MLP) for XOR\nTo solve non-linear problems like XOR, we need to add a hidden layer. This is a Multilayer Perceptron (MLP). The hidden layer allows the network to learn non-linear combinations of the inputs. We also switch to a smooth activation function like the Sigmoid function to enable gradient-based learning via backpropagation.\nMathematically,\nSigmoid function: \\(\\sigma(x) = \\frac{1}{1 + e^{-x}}\\)\n\n# Activation function and its derivative\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\ny_sigmoid = sigmoid(x_vals)\ny_sigmoid_deriv = sigmoid_derivative(y_sigmoid)\n\nplt.figure(figsize=(6, 6))\nplt.plot(x_vals, y_sigmoid, label='Sigmoid')\nplt.plot(x_vals, y_sigmoid_deriv, label='Sigmoid Derivative', linestyle='--')\nplt.title('Sigmoid Function and its Derivative')\nplt.xlabel('Input value (x)')\nplt.ylabel('Output value')\nplt.legend()\n\n\n\n\n\n\n\n\n\ndef draw_mlp_architecture(input_size, hidden_size, output_size):\n    fig, ax = plt.subplots(figsize=(6, 4))\n    ax.axis('off')\n\n    # Circle radius\n    r = 0.1\n\n    # Layer x-positions\n    x_input = 0.5\n    x_hidden = 2\n    x_output = 3.5\n\n    # Draw input layer\n    for i in range(input_size):\n        y = 1.5 - i * 0.75\n        ax.add_patch(plt.Circle((x_input, y), r, color='skyblue', ec='black'))\n        ax.text(x_input - 0.3, y, f\"$x_{i+1}$\", fontsize=12)\n\n    # Draw hidden layer\n    for j in range(hidden_size):\n        y = 1.5 - j * 0.75\n        ax.add_patch(plt.Circle((x_hidden, y), r, color='lightgreen', ec='black'))\n        ax.text(x_hidden, y, f\"$h_{j+1}$\", fontsize=12, ha='center', va='center')\n\n    # Draw output layer\n    for k in range(output_size):\n        y = 0.75  # Always one output neuron here\n        ax.add_patch(plt.Circle((x_output, y), r, color='salmon', ec='black'))\n        ax.text(x_output + 0.2, y, \"$\\\\hat{y}$\", fontsize=12)\n\n    # Arrows from input to hidden\n    for i in range(input_size):\n        y1 = 1.5 - i * 0.75\n        for j in range(hidden_size):\n            y2 = 1.5 - j * 0.75\n            ax.annotate(\"\", xy=(x_hidden - r, y2), xytext=(x_input + r, y1),\n                        arrowprops=dict(arrowstyle='-&gt;', lw=1))\n\n    # Arrows from hidden to output\n    for j in range(hidden_size):\n        y2 = 1.5 - j * 0.75\n        y_out = 0.75\n        ax.annotate(\"\", xy=(x_output - r, y_out), xytext=(x_hidden + r, y2),\n                    arrowprops=dict(arrowstyle='-&gt;', lw=1))\n\n    ax.set_title(\"MLP Architecture for XOR\", fontsize=14)\n    plt.xlim(0, 4)\n    plt.ylim(-0.5, 2.0)\n    plt.tight_layout()\n    plt.show()\n\n\nimport numpy as np\n\nclass MLP_XOR:\n    def __init__(self, input_size=2, hidden_size=2, output_size=1):\n        # Initialize weights randomly to break symmetry\n        self.weights_hidden = np.random.uniform(size=(input_size, hidden_size))\n        self.weights_output = np.random.uniform(size=(hidden_size, output_size))\n        \n        # Biases can be initialized to zero or randomly\n        self.bias_hidden = np.random.uniform(size=(1, hidden_size))\n        self.bias_output = np.random.uniform(size=(1, output_size))\n\n    def forward(self, X):\n        # Forward propagation\n        self.hidden_activation = sigmoid(np.dot(X, self.weights_hidden) + self.bias_hidden)\n        self.output = sigmoid(np.dot(self.hidden_activation, self.weights_output) + self.bias_output)\n        return self.output\n\n    def backward(self, X, y, output, lr):\n        # error\n        output_error = y - output\n        output_delta = output_error * sigmoid_derivative(output)\n\n        hidden_error = output_delta.dot(self.weights_output.T)\n        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_activation)\n\n        # Update weights and biases\n        self.weights_output += self.hidden_activation.T.dot(output_delta) * lr\n        self.weights_hidden += X.T.dot(hidden_delta) * lr\n        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * lr\n        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * lr\n\n    def train(self, X, y, epochs=10000, lr=0.1):\n        y = y.reshape(-1, 1) # Ensure y is a column vector\n        for i in range(epochs):\n            output = self.forward(X)\n            self.backward(X, y, output, lr)\n            if (i % 1000) == 0:\n                loss = np.mean(np.square(y - output))\n                print(f\"Epoch {i} Loss: {loss:.4f}\")\n\n    def predict(self, X):\n        return (self.forward(X) &gt; 0.5).astype(int)\n\n    def show(self):\n        draw_mlp_architecture(\n            input_size=self.weights_hidden.shape[0],\n            hidden_size=self.weights_hidden.shape[1],\n            output_size=self.weights_output.shape[1]\n        )\n\n\nmlp = MLP_XOR()\nmlp.show()\n\n\n\n\n\n\n\n\n\n\nX_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny_xor = np.array([0, 1, 1, 0])\n\nmlp_xor = MLP_XOR()\nmlp_xor.train(X_xor, y_xor)\n\nEpoch 0 Loss: 0.3274\nEpoch 1000 Loss: 0.2498\nEpoch 2000 Loss: 0.2479\nEpoch 3000 Loss: 0.2306\nEpoch 4000 Loss: 0.1784\nEpoch 5000 Loss: 0.0817\nEpoch 6000 Loss: 0.0219\nEpoch 7000 Loss: 0.0104\nEpoch 8000 Loss: 0.0065\nEpoch 9000 Loss: 0.0046\n\n\n\npredictions = mlp_xor.predict(X_xor)\n\nprint(\"\\n--- MLP for XOR Results ---\")\nprint(f\"Expected Output: {y_xor}\")\nprint(f\"MLP Final Output: {predictions.flatten()}\")\naccuracy = np.sum(y_xor == predictions.flatten()) / len(y_xor)\nprint(f\"Accuracy: {accuracy * 100}%\")\nprint(\"\\nSuccess! The MLP with a hidden layer correctly learns the XOR function.\")\n\n\n--- MLP for XOR Results ---\nExpected Output: [0 1 1 0]\nMLP Final Output: [0 1 1 0]\nAccuracy: 100.0%\n\nSuccess! The MLP with a hidden layer correctly learns the XOR function."
  },
  {
    "objectID": "posts/basic_deep_learning.html#simple-neural-network-for-mnist-from-scratch",
    "href": "posts/basic_deep_learning.html#simple-neural-network-for-mnist-from-scratch",
    "title": "Deep Learning Concepts",
    "section": "3. Simple Neural Network for MNIST from Scratch",
    "text": "3. Simple Neural Network for MNIST from Scratch\nNow, we’ll scale up to a more complex problem: classifying handwritten digits from the MNIST dataset. We will build everything from scratch.\n\nArchitecture: Input Layer (784 neurons) -&gt; Hidden Layer (128 neurons, ReLU activation) -&gt; Output Layer (10 neurons, Softmax activation)\nLoss Function: Categorical Cross-Entropy\nOptimizer: Stochastic Gradient Descent (SGD)\n\nNote: We use torchvision for convenience to download and load the dataset, but all network logic is pure NumPy.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\n\n\ntransform = transforms.ToTensor()\ntrain_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\ntest_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\nlen(train_data), len(test_data)\n\n(60000, 10000)\n\n\n\n# convert to numpy\n# flatten the images\n# normalize the data\nprint(train_data.data.numpy().shape)\n\nX_train = train_data.data.numpy().reshape(len(train_data), -1) / 255.0\ny_train_raw = train_data.targets.numpy()\n\nX_test = test_data.data.numpy().reshape(len(test_data), -1) / 255.0\ny_test_raw = test_data.targets.numpy()\n\nX_train.shape\n\n(60000, 28, 28)\n\n\n(60000, 784)\n\n\n\n# One-hot encode labels\ndef one_hot(y, num_classes):\n    return np.eye(num_classes)[y]\n\n\n# demonstrating one-hot\nlabel = 7\nbatch_of_labels = np.array([3, 0, 9, 1])\nnum_classes = 10\n\none_hot_label = one_hot(label, num_classes)\none_hot_batch = one_hot(batch_of_labels, num_classes)\n\nprint(f\"Original label: {label}\")\nprint(f\"One-hot vector: {one_hot_label}\\n\")\n\nprint(f\"Original batch: {batch_of_labels}\")\nprint(f\"One-hot batch:\\n{one_hot_batch}\")\n\nOriginal label: 7\nOne-hot vector: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n\nOriginal batch: [3 0 9 1]\nOne-hot batch:\n[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n\n\n\ny_train = one_hot(y_train_raw, 10)\ny_test = one_hot(y_test_raw, 10)\n\ny_train[:2, :], y_test[:2, :]\n\n(array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]))\n\n\n\n\nprint(f\"Training data shape: {X_train.shape}\")\nprint(f\"Training labels shape: {y_train.shape}\")\n\nTraining data shape: (60000, 784)\nTraining labels shape: (60000, 10)\n\n\n\ndef relu(x):\n    return np.maximum(0, x)\n\ndef relu_derivative(x):\n    return np.where(x &gt; 0, 1, 0)\n\ny_relu = relu(x_vals)\ny_relu_deriv = relu_derivative(x_vals)\n\nplt.plot(x_vals, y_relu, label='ReLU')\nplt.plot(x_vals, y_relu_deriv, label='ReLU Derivative', linestyle='--')\nplt.title('ReLU Function and its Derivative')\nplt.xlabel('Input value (x)')\nplt.ylabel('Output value')\nplt.legend()\n\n\n\n\n\n\n\n\n\ndef softmax(x):\n    exps = np.exp(x - np.max(x, axis=1, keepdims=True)) # difference for stability\n    return exps / np.sum(exps, axis=1, keepdims=True)\n\n# extra bracket for batch dimension\nlogits = np.array([[2.0, 1.0, 0.1, 3.0, -1.0]]) \n\nprobabilities = softmax(logits)\n\n# flatten to plot\nprobabilities_flatten = probabilities.flatten()\n\nprint(f\"Original Logits: {logits.flatten()}\")\nprint(f\"Probabilities after Softmax: {np.round(probabilities, 3)}\")\nprint(f\"Sum of probabilities: {np.sum(probabilities):.2f}\")\n\nclass_indices = [f'Class {i}' for i in range(len(probabilities_flatten))]\nplt.bar(class_indices, probabilities_flatten)\nplt.title('Softmax Function Output')\nplt.xlabel('Class')\nplt.ylabel('Probability')\nplt.ylim(0, 1)\nprint(\"Softmax Function: Converts raw scores (logits) into a probability distribution. The class with the highest logit gets the highest probability.\")\n\nOriginal Logits: [ 2.   1.   0.1  3.  -1. ]\nProbabilities after Softmax: [[0.233 0.086 0.035 0.634 0.012]]\nSum of probabilities: 1.00\nSoftmax Function: Converts raw scores (logits) into a probability distribution. The class with the highest logit gets the highest probability.\n\n\n\n\n\n\n\n\n\n\n# penalty should grow exponentially as the model gets more confident and wrong\ndef cross_entropy_loss(y_pred, y_true):\n    # y_true contains labels for entire batch \n    # Clip to avoid log(0)\n    y_pred_clipped = np.clip(y_pred, 1e-12, 1. - 1e-12)\n\n    # so divided by batch size for averaging loss per sample\n    # y_true is either 0 or 1, one_hot\n    return -np.sum(y_true * np.log(y_pred_clipped)) / y_true.shape[0]\n\n\ny_true = np.array([[0, 0, 1, 0]])\n\npredicted_probs_for_correct_class = np.linspace(0.01, 0.99, 200)\n\n# basic curve\nlosses_curve = [-np.log(p) for p in predicted_probs_for_correct_class]\n\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.figure(figsize=(10, 6))\nplt.plot(predicted_probs_for_correct_class, losses_curve, color='royalblue', label='Loss Curve')\n\n# 3 Key Cases \ncases = {\n    'A': 0.95, # High Confidence, Correct\n    'B': 0.50, # Medium Confidence\n    'C': 0.05  # Low Confidence, Wrong\n}\n\ncolors = {'A': 'green', 'B': 'orange', 'C': 'red'}\nprint(\"--- Predictions and Losses for 3 Cases ---\\n\")\n\nfor case, prob in cases.items():\n    remaining_prob = (1 - prob) / 3\n\n    # sharing same for the rest of the 3 classes\n    y_pred = np.array([remaining_prob, remaining_prob, prob, remaining_prob])\n    loss = cross_entropy_loss(y_pred.reshape(1, -1), y_true)\n\n    print(f\"--- Case {case} ---\")\n    print(f\"Prediction Vector (y_pred): {np.round(y_pred, 4)}\")\n    print(f\"Corresponding Loss: {loss:.4f}\\n\")\n\n    # Marking the points\n    plt.plot(prob, loss, 'o', color=colors[case], markersize=10, label=f'Case {case}')\n\nplt.title('Cross-Entropy Loss Curve', fontsize=16)\nplt.xlabel('Predicted Probability for the Correct Class', fontsize=12)\nplt.ylabel('Calculated Loss', fontsize=12)\nplt.legend()\nplt.grid(True)\nplt.ylim(0, 5)\nplt.show()\n\n--- Predictions and Losses for 3 Cases ---\n\n--- Case A ---\nPrediction Vector (y_pred): [0.0167 0.0167 0.95   0.0167]\nCorresponding Loss: 0.0513\n\n--- Case B ---\nPrediction Vector (y_pred): [0.1667 0.1667 0.5    0.1667]\nCorresponding Loss: 0.6931\n\n--- Case C ---\nPrediction Vector (y_pred): [0.3167 0.3167 0.05   0.3167]\nCorresponding Loss: 2.9957\n\n\n\n\n\n\n\n\n\n\n\nSimple computation graph to understand gradients formula computation\n\n\n\nbackprop.png\n\n\nCross entropy backpropagation: https://medium.com/data-science/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9\n\nclass SimpleNN_MNIST:\n    def __init__(self, input_size, hidden_size, output_size):\n        # He initialization for weights\n        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)\n        self.b1 = np.zeros((1, hidden_size))\n        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)\n        self.b2 = np.zeros((1, output_size))\n        \n    def forward(self, X):\n        # Store intermediate values for backpropagation\n        self.Z1 = X @ self.W1 + self.b1\n        self.A1 = relu(self.Z1)\n        self.Z2 = self.A1 @ self.W2 + self.b2\n        self.A2 = softmax(self.Z2)\n        return self.A2\n    \n    def backward(self, X, y_true):\n        # Number of samples in the batch\n        m = y_true.shape[0] \n    \n        # -----------------------------------\n        # Output Layer Gradients\n        # -----------------------------------\n    \n        # Gradient of the loss with respect to Z2 (pre-activation of the output layer)\n        # Since we're using Softmax + Cross-Entropy Loss, the gradient simplifies to:\n        # dZ2 = A2 - y_true\n        # A2 is the output from softmax, y_true is one-hot encoded ground truth\n        dZ2 = self.A2 - y_true\n    \n        # Gradient of the loss with respect to W2 (weights between hidden and output layers)\n        # Using the chain rule: dW2 = (A1^T @ dZ2) / m\n        # A1: activations from hidden layer, shape (m, hidden_dim)\n        # dZ2: error term for output layer, shape (m, output_dim)\n        # A1.T @ dZ2 results in shape (hidden_dim, output_dim)\n        self.dW2 = (self.A1.T @ dZ2) / m\n    \n        # Gradient of the loss with respect to b2 (bias of the output layer)\n        # Sum over the batch dimension to get bias gradient: shape (1, output_dim)\n        self.db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n\n    \n        # Backpropagating the error to the hidden layer\n        # dA1 = dZ2 @ W2^T\n        # W2.T: shape (output_dim, hidden_dim)\n        # dZ2: shape (m, output_dim)\n        # dA1: shape (m, hidden_dim), error signal for hidden layer outputs (A1)\n        dA1 = dZ2 @ self.W2.T\n    \n        # Applying the derivative of the ReLU activation function\n        # ReLU'(Z1) is 1 where Z1 &gt; 0, else 0\n        # Element-wise multiply with dA1 to get dZ1 (gradient wrt pre-activation of hidden layer)\n        dZ1 = dA1 * relu_derivative(self.Z1)\n        self.dW1 = (X.T @ dZ1) / m\n        self.db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n\n    def update_params(self, lr):\n        # Basic SGD optimizer\n        self.W1 -= lr * self.dW1\n        self.b1 -= lr * self.db1\n        self.W2 -= lr * self.dW2\n        self.b2 -= lr * self.db2\n        \n    def train(self, X_train, y_train, X_test, y_test_raw, epochs, lr, batch_size):\n        history = {'loss': [], 'accuracy': []}\n        num_batches = len(X_train) // batch_size\n        \n        for epoch in range(epochs):\n            # Shuffle \n            permutation = np.random.permutation(len(X_train))\n            X_train_shuffled = X_train[permutation]\n            y_train_shuffled = y_train[permutation]\n            \n            epoch_loss = 0\n            for i in tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{epochs}\"):\n                # Create mini-batch\n                start = i * batch_size\n                end = start + batch_size\n                X_batch = X_train_shuffled[start:end]\n                y_batch = y_train_shuffled[start:end]\n                \n                y_pred = self.forward(X_batch)\n                epoch_loss += cross_entropy_loss(y_pred, y_batch)\n                self.backward(X_batch, y_batch)\n                self.update_params(lr)\n            \n            # Calculate loss and accuracy at the end of epoch\n            avg_loss = epoch_loss / num_batches\n            \n            # Evaluate on test set\n            y_pred_test = self.predict(X_test)\n            accuracy = np.sum(y_pred_test == y_test_raw) / len(y_test_raw)\n            \n            history['loss'].append(avg_loss)\n            history['accuracy'].append(accuracy)\n            print(f'Epoch {epoch+1} - Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n        return history\n\n    def predict(self, X):\n        y_pred_probs = self.forward(X)\n        return np.argmax(y_pred_probs, axis=1)\n\n\n# --- 3. Train the Network and Plot Results ---\n\n# Hyperparameters\nINPUT_SIZE = 784\nHIDDEN_SIZE = 128\nOUTPUT_SIZE = 10\nEPOCHS = 10\nLEARNING_RATE = 0.1\nBATCH_SIZE = 64\n\nscratch_nn = SimpleNN_MNIST(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\nhistory = scratch_nn.train(X_train, y_train, X_test, y_test_raw, EPOCHS, LEARNING_RATE, BATCH_SIZE)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\nfig.suptitle('From-Scratch Model Training', fontsize=16)\n\nax1.plot(history['loss'])\nax1.set_title('Training Loss')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Cross-Entropy Loss')\n\nax2.plot(history['accuracy'])\nax2.set_title('Test Accuracy')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy')\n\nplt.show()\n\nEpoch 1/10: 100%|██████████████████████| 937/937 [00:02&lt;00:00, 315.13it/s]\n\n\nEpoch 1 - Loss: 0.3735, Test Accuracy: 0.9359\n\n\nEpoch 2/10: 100%|██████████████████████| 937/937 [00:01&lt;00:00, 536.68it/s]\n\n\nEpoch 2 - Loss: 0.2000, Test Accuracy: 0.9515\n\n\nEpoch 3/10: 100%|██████████████████████| 937/937 [00:02&lt;00:00, 428.29it/s]\n\n\nEpoch 3 - Loss: 0.1509, Test Accuracy: 0.9600\n\n\nEpoch 4/10: 100%|██████████████████████| 937/937 [00:01&lt;00:00, 569.65it/s]\n\n\nEpoch 4 - Loss: 0.1223, Test Accuracy: 0.9645\n\n\nEpoch 5/10: 100%|██████████████████████| 937/937 [00:01&lt;00:00, 546.63it/s]\n\n\nEpoch 5 - Loss: 0.1034, Test Accuracy: 0.9675\n\n\nEpoch 6/10: 100%|██████████████████████| 937/937 [00:03&lt;00:00, 308.86it/s]\n\n\nEpoch 6 - Loss: 0.0895, Test Accuracy: 0.9693\n\n\nEpoch 7/10: 100%|██████████████████████| 937/937 [00:01&lt;00:00, 546.72it/s]\n\n\nEpoch 7 - Loss: 0.0784, Test Accuracy: 0.9728\n\n\nEpoch 8/10: 100%|██████████████████████| 937/937 [00:01&lt;00:00, 528.95it/s]\n\n\nEpoch 8 - Loss: 0.0700, Test Accuracy: 0.9745\n\n\nEpoch 9/10: 100%|██████████████████████| 937/937 [00:02&lt;00:00, 467.59it/s]\n\n\nEpoch 9 - Loss: 0.0624, Test Accuracy: 0.9752\n\n\nEpoch 10/10: 100%|█████████████████████| 937/937 [00:01&lt;00:00, 492.77it/s]\n\n\nEpoch 10 - Loss: 0.0565, Test Accuracy: 0.9761"
  },
  {
    "objectID": "posts/basic_deep_learning.html#weight-initialization-techniques",
    "href": "posts/basic_deep_learning.html#weight-initialization-techniques",
    "title": "Deep Learning Concepts",
    "section": "4. Weight Initialization Techniques",
    "text": "4. Weight Initialization Techniques\nProper weight initialization is crucial for preventing gradients from vanishing (becoming too small) or exploding (becoming too large) during training. Here are a few common techniques implemented from scratch.\n\nZeros Initialization: A bad practice that causes all neurons in a layer to learn the same thing.\nRandom Normal: Breaks symmetry, but can lead to vanishing/exploding gradients if not scaled correctly.\nXavier/Glorot Initialization: Scales weights based on the number of input neurons (n_in). Good for Tanh/Sigmoid activations. Formula: \\(W \\sim N(0, \\sqrt{1/n_{in}})\\).\nHe Initialization: Scales weights based on n_in. Designed for ReLU-based activations. Formula: \\(W \\sim N(0, \\sqrt{2/n_{in}})\\).\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import gaussian_kde\n\n# Initialization \ndef zeros_init(n_in, n_out):\n    return np.zeros((n_out, n_in))\n\ndef random_normal_init(n_in, n_out):\n    return np.random.randn(n_out, n_in) * 0.01\n\ndef xavier_init(n_in, n_out):\n    return np.random.randn(n_out, n_in) * np.sqrt(1.0 / n_in)\n\ndef he_init(n_in, n_out):\n    return np.random.randn(n_out, n_in) * np.sqrt(2.0 / n_in)\n\n# plot density curves \ndef plot_density(weights, label, color):\n    flat_weights = weights.flatten()\n    density = gaussian_kde(flat_weights)\n    x_vals = np.linspace(flat_weights.min(), flat_weights.max(), 200)\n    plt.plot(x_vals, density(x_vals), label=label, color=color)\n\n# Layer dimensions\nn_in, n_out = 784, 128\n\ninitializations = {\n    \"Random Normal\": (random_normal_init(n_in, n_out), 'blue'),\n    \"Xavier\": (xavier_init(n_in, n_out), 'red'),\n    \"He\": (he_init(n_in, n_out), 'green'),\n    \"Zeros\": (zeros_init(n_in, n_out), 'black')  \n}\n\n# Print stats and plot densities (excluding Zeros)\nplt.figure(figsize=(10, 5))\nfor name, (weights, color) in initializations.items():\n    mean, std = weights.mean(), weights.std()\n    print(f\"{name:&lt;15} | Mean: {mean:&gt;7.4f}, Std: {std:&gt;7.4f}\")\n    if name != \"Zeros\":\n        plot_density(weights, name, color)\n\nplt.title(\"Weight Initialization Density (Excl. Zeros)\")\nplt.xlabel(\"Weight Value\")\nplt.ylabel(\"Density\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Plot Zeros separately\nplt.figure(figsize=(5, 4))\nplt.hist(initializations[\"Zeros\"][0].flatten(), bins=10, color='gray')\nplt.title(\"Zeros Initialization (Separate View)\")\nplt.xlabel(\"Weight Value\")\nplt.ylabel(\"Frequency\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\nRandom Normal   | Mean:  0.0000, Std:  0.0100\nXavier          | Mean:  0.0000, Std:  0.0358\nHe              | Mean:  0.0000, Std:  0.0505\nZeros           | Mean:  0.0000, Std:  0.0000"
  },
  {
    "objectID": "posts/basic_deep_learning.html#pytorch-verification",
    "href": "posts/basic_deep_learning.html#pytorch-verification",
    "title": "Deep Learning Concepts",
    "section": "5. PyTorch Verification",
    "text": "5. PyTorch Verification\nLet’s build the exact same network in PyTorch. This helps verify that our from-scratch implementation is correct. We will use the same architecture, hyperparameters, and optimizer.\nThe final accuracy should be very close to our NumPy model.\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\n\nX_train_t = torch.tensor(X_train, dtype=torch.float32)\ny_train_t = torch.tensor(y_train_raw, dtype=torch.long) \nX_test_t = torch.tensor(X_test, dtype=torch.float32)\ny_test_t = torch.tensor(y_test_raw, dtype=torch.long)\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\ntest_dataset = TensorDataset(X_test_t, y_test_t)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nclass PyTorchNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(PyTorchNN, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        \n        # Apply He initialization\n        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out \n\n\npytorch_nn = PyTorchNN(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.SGD(pytorch_nn.parameters(), lr=LEARNING_RATE)\n\npytorch_history = {'loss': [], 'accuracy': []}\n\nfor epoch in range(EPOCHS):\n    epoch_loss = 0\n    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")):\n        outputs = pytorch_nn(inputs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = pytorch_nn(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    avg_loss = epoch_loss / len(train_loader)\n    accuracy = correct / total\n    \n    pytorch_history['loss'].append(avg_loss)\n    pytorch_history['accuracy'].append(accuracy)\n    print(f'Epoch {epoch+1} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n\nEpoch 1/10: 100%|█████████████████████| 938/938 [00:00&lt;00:00, 1080.91it/s]\n\n\nEpoch 1 - Loss: 0.3656, Accuracy: 0.9382\n\n\nEpoch 2/10: 100%|█████████████████████| 938/938 [00:00&lt;00:00, 1130.23it/s]\n\n\nEpoch 2 - Loss: 0.1950, Accuracy: 0.9547\n\n\nEpoch 3/10: 100%|█████████████████████| 938/938 [00:00&lt;00:00, 1095.94it/s]\n\n\nEpoch 3 - Loss: 0.1472, Accuracy: 0.9615\n\n\nEpoch 4/10: 100%|██████████████████████| 938/938 [00:00&lt;00:00, 996.78it/s]\n\n\nEpoch 4 - Loss: 0.1205, Accuracy: 0.9628\n\n\nEpoch 5/10: 100%|██████████████████████| 938/938 [00:01&lt;00:00, 853.66it/s]\n\n\nEpoch 5 - Loss: 0.1021, Accuracy: 0.9704\n\n\nEpoch 6/10: 100%|██████████████████████| 938/938 [00:01&lt;00:00, 857.51it/s]\n\n\nEpoch 6 - Loss: 0.0882, Accuracy: 0.9725\n\n\nEpoch 7/10: 100%|██████████████████████| 938/938 [00:00&lt;00:00, 979.19it/s]\n\n\nEpoch 7 - Loss: 0.0776, Accuracy: 0.9717\n\n\nEpoch 8/10: 100%|██████████████████████| 938/938 [00:01&lt;00:00, 842.42it/s]\n\n\nEpoch 8 - Loss: 0.0690, Accuracy: 0.9751\n\n\nEpoch 9/10: 100%|█████████████████████| 938/938 [00:00&lt;00:00, 1029.96it/s]\n\n\nEpoch 9 - Loss: 0.0624, Accuracy: 0.9755\n\n\nEpoch 10/10: 100%|█████████████████████| 938/938 [00:00&lt;00:00, 951.11it/s]\n\n\nEpoch 10 - Loss: 0.0562, Accuracy: 0.9775\n\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\nfig.suptitle('From-Scratch vs PyTorch Model Comparison', fontsize=16)\n\nax1.plot(history['loss'], label='From Scratch')\nax1.plot(pytorch_history['loss'], label='PyTorch', linestyle='--')\nax1.set_title('Training Loss Comparison')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Cross-Entropy Loss')\nax1.legend()\n\nax2.plot(history['accuracy'], label='From Scratch')\nax2.plot(pytorch_history['accuracy'], label='PyTorch', linestyle='--')\nax2.set_title('Test Accuracy Comparison')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy')\nax2.legend()\n\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A learning journal — sharing what I discover, build, and experiment with."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blogs",
    "section": "",
    "text": "Brain MRI Detection with Interpretability\n\n\n\nvit\n\nmedical-imaging\n\nattention_rollout\n\ngrad-cam\n\n\n\nUse of vision transformer, training them, and adding interpretability to the classification problem\n\n\n\n\n\nAug 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning Concepts\n\n\n\nmachine-learning\n\ntutorials\n\ndeep-learning\n\n\n\nA simple intro to deep learning from scratch, and using Pytorch.\n\n\n\n\n\nAug 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Learning in Pytorch\n\n\n\nmachine-learning\n\ntutorials\n\ndeep-learning\n\npytorch\n\nsvhn\n\n\n\nFull training script of a deep learning model using pytorch\n\n\n\n\n\nAug 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPytorch Grad!\n\n\n\nmachine-learning\n\ntutorials\n\ndeep-learning\n\npytorch\n\n\n\nHow Gradients Work in Pytorch; A simple short implementation\n\n\n\n\n\nAug 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDemystifying AdaBoost\n\n\n\nboosting\n\nmachine-learning\n\nada-boosting\n\nsklearn\n\n\n\nBuilding the AdaBoost Algorithm from Scratch in Python\n\n\n\n\n\nSep 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting Comparison\n\n\n\nboosting\n\nmachine-learning\n\ngradient-boosting\n\nada-boosting\n\nsklearn\n\n\n\nAdaBoost vs. Gradient Boosting in Python\n\n\n\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Gram-Schmidt\n\n\n\nvectors\n\nmachine-learning\n\nstatistics\n\nnumpy\n\n\n\nThe Math and Code Behind Orthonormalization\n\n\n\n\n\nJul 15, 2024\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/full_workflow_dl.html",
    "href": "posts/full_workflow_dl.html",
    "title": "Deep Learning in Pytorch",
    "section": "",
    "text": "Basic Intro\nThis blog depicts a basic CNN model used for image classification using SVHN dataset. The objective is to give an overview of how datasets are required to be loaded, how model architectures are to be made using pytorch library, and how overall training works.\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\n# Define transformations for the SVHN dataset\n# Convert images to PyTorch Tensors\n# Normalize the tensors. The values (0.5, 0.5, 0.5) are standard for normalizing to [-1, 1]\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_dataset = torchvision.datasets.SVHN(root='./data', split='train',\n                                        download=True, transform=transform)\n\nval_dataset = torchvision.datasets.SVHN(root='./data', split='test',\n                                       download=True, transform=transform)\n\nlen(train_dataset), len(val_dataset)\n\n(73257, 26032)\n\n\n\ndef imshow(img, title=None):\n    img = img / 2 + 0.5  # unnormalize [-1, 1] -&gt; [0, 1]\n    np_img = img.numpy()\n    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n    if title:\n        plt.title(title)\n    plt.axis(\"off\")\n\nprint(\"Random samples from SVHN training set:\")\nfig, axes = plt.subplots(1, 5, figsize=(12, 3))\nfor i in range(5):\n    idx = torch.randint(0, len(train_dataset), (1,)).item()\n    img, label = train_dataset[idx]\n    plt.subplot(1, 5, i+1)\n    imshow(img)\n    plt.title(f\"Label: {label}\")\n    plt.axis(\"off\")\nplt.show()\n\nRandom samples from SVHN training set:\n\n\n\n\n\n\n\n\n\n\nBATCH_SIZE = 64\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(f\"Data loaded. Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\\n\")\n\nData loaded. Training samples: 73257, Validation samples: 26032\n\n\n\n\ndataiter = iter(train_loader)\nimages, labels = next(dataiter)\n\n# Show the batch\nprint(\"A batch from the DataLoader:\")\nimshow(torchvision.utils.make_grid(images, nrow=8),\n       title=\" \".join(str(label.item()) for label in labels))\nplt.show()\n\nA batch from the DataLoader:\n\n\n\n\n\n\n\n\n\n\n\nModel must learn to focus on the central digit and ignore the extra context\n\nclasses = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n\nprint(\"Step 2: Model Definition\")\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(SimpleCNN, self).__init__()\n        # SVHN images are 3x32x32 (3 color channels)\n        self.features = nn.Sequential(\n            # Input: 3x32x32\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1), # Output: 16x32x32\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2), # Output: 16x16x16\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), # Output: 32x16x16\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2) # Output: 32x8x8\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(32 * 8 * 8, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n\nmodel = SimpleCNN(num_classes=10)\nprint(\"Model architecture:\")\nprint(model)\nprint(\"\\n\")\n\nStep 2: Model Definition\nModel architecture:\nSimpleCNN(\n  (features): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU()\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=2048, out_features=128, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=128, out_features=10, bias=True)\n  )\n)\n\n\n\n\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nNUM_EPOCHS = 20\nfor epoch in range(NUM_EPOCHS):\n    model.train() \n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {running_loss/len(train_loader):.4f}\")\n\nprint(\"Training finished.\\n\")\n\nEpoch [1/20], Loss: 0.9173\nEpoch [2/20], Loss: 0.4778\nEpoch [3/20], Loss: 0.4011\nEpoch [4/20], Loss: 0.3499\nEpoch [5/20], Loss: 0.3119\nEpoch [6/20], Loss: 0.2827\nEpoch [7/20], Loss: 0.2563\nEpoch [8/20], Loss: 0.2327\nEpoch [9/20], Loss: 0.2116\nEpoch [10/20], Loss: 0.1927\nEpoch [11/20], Loss: 0.1746\nEpoch [12/20], Loss: 0.1595\nEpoch [13/20], Loss: 0.1442\nEpoch [14/20], Loss: 0.1314\nEpoch [15/20], Loss: 0.1208\nEpoch [16/20], Loss: 0.1081\nEpoch [17/20], Loss: 0.1003\nEpoch [18/20], Loss: 0.0915\nEpoch [19/20], Loss: 0.0826\nEpoch [20/20], Loss: 0.0747\nTraining finished.\n\n\n\n\nmodel.eval() \nall_preds = []\nall_labels = []\n\n# `torch.no_grad()` disables gradient calculation for efficiency\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        all_preds.extend(predicted.numpy())\n        all_labels.extend(labels.numpy())\n\naccuracy = accuracy_score(all_labels, all_preds)\nprecision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n\nprint(f\"Validation Accuracy: {accuracy:.4f}\")\nprint(f\"Validation Precision: {precision:.4f}\")\nprint(f\"Validation Recall: {recall:.4f}\")\nprint(f\"Validation F1 Score: {f1:.4f}\\n\")\n\nValidation Accuracy: 0.8778\nValidation Precision: 0.8787\nValidation Recall: 0.8778\nValidation F1 Score: 0.8778\n\n\n\n\n# model.state_dict()\n\n\nprint(\"Step 5: Saving and Loading the Model\")\n\nMODEL_PATH = \"svhn_cnn_weights.pth\"\ntorch.save(model.state_dict(), MODEL_PATH)\nprint(f\"Model saved to {MODEL_PATH}\")\n\nStep 5: Saving and Loading the Model\nModel saved to svhn_cnn_weights.pth\n\n\n\nnew_model = SimpleCNN(num_classes=10)\nnew_model.load_state_dict(torch.load(MODEL_PATH))\nprint(\"Model weights loaded into a new instance.\\n\")\n\nModel weights loaded into a new instance.\n\n\n\n\nprint(\"Step 6: Inference on New Data\")\n\nnew_data_point, true_label_idx = val_dataset[0]\nnew_data_point = new_data_point.unsqueeze(0)\n\nnew_model.eval()\n\nwith torch.no_grad():\n    prediction_logits = new_model(new_data_point)\n    # Get the class with the highest score\n    predicted_class_idx = torch.argmax(prediction_logits, dim=1).item()\n\nprint(f\"True Label: {classes[true_label_idx]}\")\nprint(f\"Predicted Class: {classes[predicted_class_idx]}\")\n\nStep 6: Inference on New Data\nTrue Label: 5\nPredicted Class: 5"
  },
  {
    "objectID": "posts/Boosting-Comparison/AdaBoost_GradientBoost.html",
    "href": "posts/Boosting-Comparison/AdaBoost_GradientBoost.html",
    "title": "Boosting Comparison",
    "section": "",
    "text": "Table of Contents\n\nIntroduction\nAdaBoost\nGradientBoost\nVisualization of Feature Importance\nConclusion\n\n\n\nIntroduction\nBoosting algorithms are a powerful class of ensemble methods that build models sequentially, with each new model attempting to correct the errors of its predecessor. Two of the most famous boosting algorithms are AdaBoost and Gradient Boosting. While they share a common philosophy, they differ in a crucial way: how they correct the previous errors.\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport numpy as np \nimport sklearn \nfrom sklearn import metrics \nfrom sklearn.datasets import load_iris\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport matplotlib.pyplot as plt \n\nHere, we load iris dataset, to implement both of the boosting algorithm to check the performance.\n\niris = load_iris()\niris_df = data1 = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n                     columns= iris['feature_names'] + ['target'])\niris_df.sample(10)\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\ntarget\n\n\n\n\n87\n6.3\n2.3\n4.4\n1.3\n1.0\n\n\n38\n4.4\n3.0\n1.3\n0.2\n0.0\n\n\n57\n4.9\n2.4\n3.3\n1.0\n1.0\n\n\n43\n5.0\n3.5\n1.6\n0.6\n0.0\n\n\n122\n7.7\n2.8\n6.7\n2.0\n2.0\n\n\n84\n5.4\n3.0\n4.5\n1.5\n1.0\n\n\n72\n6.3\n2.5\n4.9\n1.5\n1.0\n\n\n49\n5.0\n3.3\n1.4\n0.2\n0.0\n\n\n51\n6.4\n3.2\n4.5\n1.5\n1.0\n\n\n95\n5.7\n3.0\n4.2\n1.2\n1.0\n\n\n\n\n\n\n\n\nX = iris_df.drop(['target'], axis=1)\nY = iris_df['target']\nfeature_names = iris_df.columns.values.tolist()[:-1]\nclass_names = Y.unique().tolist()\nprint(feature_names)\nprint(class_names)\n\n['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n[0.0, 1.0, 2.0]\n\n\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape\n\n((120, 4), (30, 4), (120,), (30,))\n\n\n\ndef single_y_test_pred(y_test, y_pred) -&gt; pd.DataFrame:\n    return pd.concat(\n        [y_test.reset_index(), pd.DataFrame({\"y_pred\": y_pred})], axis=1\n    )\n\n\n\nAdaBoost\nAdaBoost works by focusing on the mistakes. In each iteration, it increases the weights of the data points that the previous model misclassified. This forces the next model to pay more attention to these ‘hard’ examples.\n\nada = sklearn.ensemble.AdaBoostClassifier()\nprint(ada) \nada = ada.fit(x_train, y_train)\ny_pred = ada.predict(x_test)\n\n# print(single_y_test_pred(y_test, y_pred))\n\nprint(sklearn.metrics.classification_report(y_test, y_pred))\n\nprint(\"Confusion matrix:\")\nprint(sklearn.metrics.confusion_matrix(y_test, y_pred, labels=class_names))\n\naccuracy_test = metrics.accuracy_score(y_test, y_pred) * 100\naccuracy_train = metrics.accuracy_score(y_train, ada.predict(x_train)) * 100\n\nprint(f\"Accuracy: {round(accuracy_test, 2)}% on Test Data\")\nprint(f\"Accuracy: {round(accuracy_train, 2)}% on Training Data\")\n\nprint(ada.score(x_test, y_test))\n\nfeature_imp_ada = pd.Series(ada.feature_importances_, index=feature_names)\nprint(feature_imp_ada)\n\nAdaBoostClassifier()\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        10\n         1.0       1.00      0.83      0.91        12\n         2.0       0.80      1.00      0.89         8\n\n    accuracy                           0.93        30\n   macro avg       0.93      0.94      0.93        30\nweighted avg       0.95      0.93      0.93        30\n\nConfusion matrix:\n[[10  0  0]\n [ 0 10  2]\n [ 0  0  8]]\nAccuracy: 93.33% on Test Data\nAccuracy: 100.0% on Training Data\n0.9333333333333333\nsepal length (cm)    0.018203\nsepal width (cm)     0.095626\npetal length (cm)    0.476359\npetal width (cm)     0.409812\ndtype: float64\n\n\nAdaBoost achieved an accuracy of 93% on the test set. The classification report shows it performs perfectly on class 0, but occasionally confuses the other classes. From the feature importance scores, we see that AdaBoost considers petal length and petal width to be almost equally important, with sepal width to be somewhat important too for making its decisions.\n\n\nGradient Boosting\nGradient Boosting takes a more generalized approach. Instead of adjusting the weights of data points, each new weak learner is trained to predict the residuals (the errors) of the previous model. It uses gradient descent to minimize the loss function of the overall model.\n\ngb = GradientBoostingClassifier()\nprint(gb) \ngb = gb.fit(x_train, y_train)\ny_pred = gb.predict(x_test)\n\n# print(single_y_test_pred(y_test, y_pred))\n\nprint(sklearn.metrics.classification_report(y_test, y_pred))\n\nprint(\"Confusion matrix:\")\nprint(sklearn.metrics.confusion_matrix(y_test, y_pred, labels=class_names))\n\naccuracy_test = metrics.accuracy_score(y_test, y_pred) * 100\naccuracy_train = metrics.accuracy_score(y_train, gb.predict(x_train)) * 100\n\nprint(f\"Accuracy: {round(accuracy_test, 2)}% on Test Data\")\nprint(f\"Accuracy: {round(accuracy_train, 2)}% on Training Data\")\n\nprint(gb.score(x_test, y_test))\n\nfeature_imp_gb = pd.Series(gb.feature_importances_, index=feature_names)\nprint(feature_imp_gb)\n\nGradientBoostingClassifier()\n              precision    recall  f1-score   support\n\n         0.0       1.00      1.00      1.00        10\n         1.0       0.91      0.83      0.87        12\n         2.0       0.78      0.88      0.82         8\n\n    accuracy                           0.90        30\n   macro avg       0.90      0.90      0.90        30\nweighted avg       0.90      0.90      0.90        30\n\nConfusion matrix:\n[[10  0  0]\n [ 0 10  2]\n [ 0  1  7]]\nAccuracy: 90.0% on Test Data\nAccuracy: 100.0% on Training Data\n0.9\nsepal length (cm)    0.000849\nsepal width (cm)     0.014108\npetal length (cm)    0.443576\npetal width (cm)     0.541467\ndtype: float64\n\n\nInterestingly, Gradient Boosting scored 90% accuracy. However, its view of the data is quite different. The feature importance plot shows that it relies heavily on petal width (almost 55% importance), giving much less weight to the sepal width in comparison to AdaBoost. This depicts a fundamental difference in how the algorithms learn.\n\n\nVisualization of both models\nHere, we visualize the feature importances for both boosting methods, to capture subtle differences in their performance.\n\n# Visualize Feature Importances\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\nfeature_imp_ada.sort_values(ascending=False).plot(kind='bar', ax=axs[0], title='AdaBoost Feature Importances')\nfeature_imp_gb.sort_values(ascending=False).plot(kind='bar', ax=axs[1], title='Gradient Boosting Feature Importances')\nplt.tight_layout()\nplt.show()\n\n# Visualize Decision Boundaries\n\ndef plot_decision_boundaries(X, y, model, title):\n    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n                         np.arange(y_min, y_max, 0.01))\n    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    plt.contourf(xx, yy, Z, alpha=0.8)\n    plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolor='k', marker='o')\n    plt.title(title)\n    plt.show()\n\n# 2 features\nX_vis_train = x_train.iloc[:, :2]\nX_vis_test = x_test.iloc[:, :2]\n\n# Train models with only the first two features for visualization\nada_vis = sklearn.ensemble.AdaBoostClassifier()\nada_vis.fit(X_vis_train, y_train)\ngb_vis = GradientBoostingClassifier()\ngb_vis.fit(X_vis_train, y_train)\n\nplot_decision_boundaries(X_vis_test, y_test, ada_vis, \"AdaBoost Decision Boundary\")\nplot_decision_boundaries(X_vis_test, y_test, gb_vis, \"Gradient Boosting Decision Boundary\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConclusion\nOn a simple dataset like Iris, both AdaBoost and Gradient Boosting can perform very well. The key takeaway is their different strategies: AdaBoost focuses on misclassified points, while Gradient Boosting focuses on minimizing overall error. Gradient Boosting is often more powerful and flexible, but AdaBoost is a fantastic algorithm for understanding the core principles of boosting."
  },
  {
    "objectID": "posts/boosting/adaboost.html",
    "href": "posts/boosting/adaboost.html",
    "title": "Demystifying AdaBoost",
    "section": "",
    "text": "Table of Contents\n\nIntroduction\nAdaBoost Algorithm\nAdaBoost Implementation\nConclusion\nReferences\n\n\n\nIntroduction\n\nEnsemble Methods\nAn ensemble method constructs set of classifiers, and then classifies new data points by taking weighted vote of their predictions. It combine decisions from multiple models to improve performance, rather than a single model.\nThere are basically 2 Methods of implementing ensemble methods that are popular in machine learning. - Random Forests - Gradient Boosted Trees\n\n\nBoosting:\n\nThis is the type of algorithm where weak learners added sequentially\nHere, weak learners are trained on previous weak models.\nFinal model is obtained by additive modeling of the weak learner models.\n\\[\n  F(x) = \\sum_{t=1}^{M} \\alpha_t h_t(x)\n  \\]\n\nIn this blog, we’ll pull back the curtain on Adaptive Boosting (AdaBoost) by implementing it from scratch.\n\nimport sklearn\nfrom sklearn.datasets import make_classification, make_moons\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\nWe generate random moon data, with 10000 number of samples.\n\n# generating random data\ndataset = make_moons(n_samples=10000,\n                     shuffle=True,\n                     #   n_classes=3,\n                     random_state=82,\n                     noise=0.3\n                     )\nprint(type(dataset))\n\n&lt;class 'tuple'&gt;\n\n\n\ndataset[0].shape, dataset[1][:5], type(dataset[1]), set(dataset[1])\n\n((10000, 2), array([1, 1, 0, 0, 0]), numpy.ndarray, {np.int64(0), np.int64(1)})\n\n\n\nX, y = dataset\nX.shape, y.shape\n\n((10000, 2), (10000,))\n\n\n\nplt.title(\"Random Dataset\")\nplt.scatter(X[:, 0], X[:, 1], marker='.',c=y)\nplt.show()\n\n\n\n\n\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=82)\nprint(f'X_train:{X_train.shape}, X_test:{X_test.shape}, y_train:{y_train.shape}, y_test:{y_test.shape}')\n\nX_train:(7000, 2), X_test:(3000, 2), y_train:(7000,), y_test:(3000,)\n\n\n\n\n\nAdaBoost Algorithm\nThe AdaBoost algorithm follows these key steps:\n\nInitialize Weights: Start by giving every data point an equal weight.\nIterate: For a set number of iterations (estimators):\n\nTrain a Weak Learner: Train a simple model on the data, using the current weights. Points with higher weights will have more influence on the model’s training.\nCalculate Weighted Error: Determine how many of the heavily-weighted points the model got wrong.\nCalculate \\(\\alpha\\): Assign a weight \\((\\alpha)\\) to the trained model. Models with lower error get a higher alpha, meaning they have more say in the final prediction.\nUpdate Weights: Increase the weights of the points the model misclassified. This is the ‘adaptive’ part; making the tough examples more important for the next iteration.\nNormalize Weights: Ensure all weights sum to 1.\n\nFinal Prediction: To classify a new point, get the prediction from all weak learners and combine them using a weighted vote, where the weights are the alpha values.\n\n\n\nAdaBoost Implementation in Python\n\nclass AdaBoost:\n    def __init__(self, n_estimators=10):\n        self.n_estimators = n_estimators\n        self.alphas = []\n        self.models = []\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n\n        # initial equal weights\n        weights = np.ones(n_samples)/n_samples\n        weights[np.isnan(weights)] = 0\n        # weights = np.array([0.0000000001 if i==0  else i for i in weights])\n        for i in range(self.n_estimators):\n            model = DecisionTreeClassifier(max_depth=1)\n\n            model.fit(X, y, sample_weight=weights)\n            y_pred = model.predict(X)\n            # print(y_pred,y)\n            \n            # calculate weighted error\n            error = np.sum(weights*(y_pred!=y))/np.sum(weights)\n            print(f\"Error for {i} model is {error:.3f}\")\n\n            # added 1e-10 so as to not get NaN values in the weights\n            alpha = 0.5*np.log((1-error)/(error + 1e-10))\n            self.alphas.append(alpha)\n            self.models.append(model)\n\n            weights *= np.exp(-alpha*y*y_pred)\n            weights /= np.sum(weights)\n\n        print(f'\\nAlphas modified into: {self.alphas}')\n\n    # tally the weighted votes from all our trained models.\n    def predict(self, X,  y):\n        n_samples, _ = X.shape\n\n        predictions = np.zeros(n_samples)\n        for alpha, model in zip(self.alphas, self.models):\n            print(f'Accuracy for single model: {accuracy_score(model.predict(X), y)}')\n            predictions += alpha*model.predict(X)\n\n        return np.sign(predictions)\n\nHere, we initialize the model to the class we just created.\n\nmodel = AdaBoost()\nmodel\n\n&lt;__main__.AdaBoost at 0x72ed6c97f4d0&gt;\n\n\n\nmodel.fit(X_train, y_train)\n\nError for 0 model is 0.196\nError for 1 model is 0.219\nError for 2 model is 0.187\nError for 3 model is 0.252\nError for 4 model is 0.252\nError for 5 model is 0.252\nError for 6 model is 0.252\nError for 7 model is 0.252\nError for 8 model is 0.252\nError for 9 model is 0.252\n\nAlphas modified into: [np.float64(0.7057423047191226), np.float64(0.6367577620190208), np.float64(0.7341725283661305), np.float64(0.542923918364508), np.float64(0.542923918364508), np.float64(0.542923918364508), np.float64(0.542923918364508), np.float64(0.542923918364508), np.float64(0.542923918364508), np.float64(0.542923918364508)]\n\n\n\naccuracy_score(model.predict(X_test, y_test),  y_test)\n\nAccuracy for single model: 0.8023333333333333\nAccuracy for single model: 0.7896666666666666\nAccuracy for single model: 0.6666666666666666\nAccuracy for single model: 0.49433333333333335\nAccuracy for single model: 0.49433333333333335\nAccuracy for single model: 0.49433333333333335\nAccuracy for single model: 0.49433333333333335\nAccuracy for single model: 0.49433333333333335\nAccuracy for single model: 0.49433333333333335\nAccuracy for single model: 0.49433333333333335\n\n\n0.8463333333333334\n\n\n\n\nConclusion\nHere, we can see the individual accuracy of model are around 50 and just 3 models have 66, 78 and 80% accuracy. However, with AdaBoosting, the learned weights are assigned get the final accuracy of 84%.\n\n\nReferences\n\nOSU paper (PDF)\n\nscikit-learn: Ensemble methods\n\nML from Scratch: AdaBoost code\n\nsklearn.datasets.make_moons"
  }
]